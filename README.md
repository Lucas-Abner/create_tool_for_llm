# create_tool_for_llm

Este projeto demonstra como criar um **agente de chat** que utiliza **ferramentas (function calling)** para responder perguntas sobre pre√ßos de passagens a√©reas.  

Ele usa o modelo **LLaMA 3** via **Ollama** e implementa uma ferramenta personalizada `get_ticket_price` para consultar valores de passagens.

---

## üìÇ Estrutura do Notebook

- **Configura√ß√£o do modelo**
  - Importa `ollama`
  - Define o modelo usado: `llama3.1:8b`

- **Mensagem de sistema**
  - Define o papel da IA como um assistente de uma companhia a√©rea chamada **FlightAI**

- **Tabela de pre√ßos**
  - Um dicion√°rio com valores de passagens de ida e volta para algumas cidades (`London`, `Paris`, `Tokyo`, `Berlin`).

- **Ferramenta: `get_ticket_price`**
  - Fun√ß√£o que recebe uma cidade e retorna o pre√ßo da passagem correspondente.

- **Descri√ß√£o da ferramenta**
  - Estrutura JSON que informa ao modelo como usar a fun√ß√£o (`name`, `description`, `parameters`).

- **Registro das ferramentas**
  - Lista `tools` que conecta a fun√ß√£o ao modelo.

- **Fun√ß√£o de chat**
  - Controla a conversa com o usu√°rio, decide quando chamar a ferramenta e retorna a resposta final.

- **Manipula√ß√£o de chamadas de ferramenta**
  - Fun√ß√£o `handle_tool_call` que executa a fun√ß√£o Python real quando o modelo solicita.

- **Interface com usu√°rio**
  - Uso de `gr.ChatInterface` para criar uma interface interativa de chat.
